{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "TEST_PERCENTAGE = 0.1\n",
    "LABELS = np.array([0, 1])\n",
    "\n",
    "# Disable print\n",
    "def blockPrint():\n",
    "    sys.stdout = open(os.devnull, \"w\")\n",
    "\n",
    "# Enable print\n",
    "def unblockPrint():\n",
    "    sys.stdout = sys.__stdout__\n",
    "\n",
    "# load from diabetes data set\n",
    "def loadDataset(file_name):\n",
    "    data = pd.read_csv(\"data/\" + file_name)\n",
    "    # print(data.head())\n",
    "    data = data.to_numpy()\n",
    "    random.seed(20)\n",
    "    random.shuffle(data)\n",
    "    no_rows = data.shape[0]\n",
    "    train = data[:int((1-TEST_PERCENTAGE)*no_rows)]\n",
    "    test = data[int((1-TEST_PERCENTAGE)*no_rows):]\n",
    "\n",
    "    return train, test\n",
    "\n",
    "\n",
    "# misclassification rate\n",
    "def getMisclassificationRate(data):\n",
    "    class_count = np.zeros(len(LABELS), dtype = int)\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        label = data[i][-1]                  # getting label\n",
    "        idx = int(np.argwhere(LABELS == label))   # finding index in LABELS\n",
    "        class_count[idx] += 1\n",
    "    prob = class_count[np.argmax(class_count)]/len(data)\n",
    "    miscls = 1-prob\n",
    "    miscls = round(miscls,2)\n",
    "    return miscls\n",
    "\n",
    "\n",
    "# gini index\n",
    "def getGiniIndex(data):\n",
    "    class_count = np.zeros(len(LABELS), dtype = int)\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        label = data[i][-1]                  # getting label\n",
    "        idx = int(np.argwhere(LABELS == label))   # finding index in LABELS\n",
    "        class_count[idx] += 1\n",
    "    gini = 1\n",
    "    # print(class_count)\n",
    "    for i in range(len(LABELS)):\n",
    "        if class_count[i] == 0:\n",
    "            continue\n",
    "        # print(class_count[i], len(data))\n",
    "        gini = round(gini - (class_count[i]/len(data))**2, 5)\n",
    "\n",
    "    return gini\n",
    "\n",
    "\n",
    "def getSplit(train_data):\n",
    "\n",
    "    gini = getGiniIndex(train_data)                         # splitting criterion\n",
    "    # print(f\"Gini index current node: {gini}\")\n",
    "\n",
    "    best_split = np.zeros((8, 2))                           # store best split for each feature\n",
    "    for col in range(train_data.shape[1]-1):                # loop for every feature\n",
    "        \n",
    "        feature = train_data[:,np.r_[col,-1]]\n",
    "\n",
    "        feature_temp = feature[:,0]\n",
    "        if len(feature_temp) == 0:                          # if branch is pure break the loop, no farther \n",
    "            break\n",
    "\n",
    "        max_val = round(feature_temp[np.argmax(feature_temp)], 2)\n",
    "        min_val = round(feature_temp[np.argmin(feature_temp)], 2)\n",
    "        step_size = round((max_val - min_val)/100, 2)\n",
    "\n",
    "        if step_size == 0:\n",
    "            step_size = 0.01\n",
    "\n",
    "        for step in np.arange(min_val, max_val, step_size): # incrementing possible split values\n",
    "\n",
    "            # -----------------------------------------------------------------------\n",
    "\n",
    "            left = []      # array of values below or equal to threshold and labels\n",
    "            right = []     # array of values above threshold and labels\n",
    "            for item in range(len(feature)):\n",
    "\n",
    "                if feature[item][0] <= step:          # left\n",
    "                    left.append(feature[item])\n",
    "                else:                                 # right\n",
    "                    right.append(feature[item])\n",
    "\n",
    "            #------------------------------------------------------------------------\n",
    "\n",
    "            # left = [item for item in feature if item[0] <= step]\n",
    "            # right = [item for item in feature if item[0] > step]\n",
    "\n",
    "            #------------------------------------------------------------------------\n",
    "\n",
    "            # left = np.argwhere(feature[:,0] <= step)\n",
    "            # right = np.argwhere(feature[:,0] > step)\n",
    "            # left_idx = np.reshape(left, (1,left.shape[0]))[0]\n",
    "            # right_idx = np.reshape(right, (1,right.shape[0]))[0]\n",
    "\n",
    "            # left = feature[left_idx,:]\n",
    "            # right = feature[right_idx,:]\n",
    "\n",
    "            #------------------------------------------------------------------------\n",
    "\n",
    "            giniL = getGiniIndex(left)\n",
    "            giniR = getGiniIndex(right)\n",
    "\n",
    "            # percentage of classification improved with split\n",
    "            improv = gini - (len(left)/len(feature))*giniL - (len(right)/len(feature))*giniR    # misclass of current node - misclass of generated nodes\n",
    "            improv = round(improv, 2)                                                          # always has to be positive\n",
    "\n",
    "            if improv > best_split[col][0]:\n",
    "                best_split[col][0] = improv\n",
    "                best_split[col][1] = step\n",
    "\n",
    "        # break\n",
    "     #print(best_split)\n",
    "    feature = np.argmax(best_split[:,0])\n",
    "    split = round(best_split[np.argmax(best_split[:,0]),1], 2)\n",
    "    improvement = best_split[np.argmax(best_split[:,0]),0]\n",
    "\n",
    "    return feature, split\n",
    "\n",
    "\n",
    "def getNodePoints(train_data, feature, split):\n",
    "\n",
    "    left_idx = np.argwhere(train_data[:,feature] <= split)\n",
    "    left_idx = np.reshape(left_idx, (1,left_idx.shape[0]))[0]\n",
    "\n",
    "    right_idx = np.argwhere(train_data[:,feature] > split)\n",
    "    right_idx = np.reshape(right_idx, (1,right_idx.shape[0]))[0]\n",
    "\n",
    "    left_node = np.array(train_data[left_idx, :])\n",
    "    right_node = np.array(train_data[right_idx, :])\n",
    "\n",
    "    return left_node, right_node\n",
    "\n",
    "\n",
    "def getNodeClassification(data):\n",
    "\n",
    "    if len(data) == 0:                       # if empty node\n",
    "        classification = None\n",
    "        return classification\n",
    "\n",
    "    no_zeros = np.argwhere(data[:,-1] == 0)\n",
    "    no_ones = np.argwhere(data[:,-1] == 1)\n",
    "\n",
    "    if no_zeros.shape[0] == 0:\n",
    "        classification = 1\n",
    "        return classification\n",
    "    elif no_ones.shape[0] == 0:\n",
    "        classification = 0\n",
    "        return classification\n",
    "\n",
    "\n",
    "    classification = np.argmax([no_zeros.shape[0], no_ones.shape[0]])\n",
    "\n",
    "    return classification\n",
    "\n",
    "\n",
    "class Node():\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.classification = getNodeClassification(self.data)\n",
    "\n",
    "        self.feature, self.split = getSplit(self.data)\n",
    "        self.data_left, self.data_right = getNodePoints(self.data, self.feature, self.split)\n",
    "\n",
    "\n",
    "class Tree():\n",
    "    def __init__(self, node):\n",
    "        self.root = node\n",
    "        self.depth = 0\n",
    "        self.splits_lst = []\n",
    "\n",
    "    def add(self, node, lst, cur_layer):\n",
    "        queue = []\n",
    "        queue.append(node)\n",
    "        #count = 0\n",
    "\n",
    "        while len(queue) > 0:\n",
    "\n",
    "            lst.append([queue[0].feature, queue[0].split])\n",
    "            node = queue.pop(0)\n",
    "\n",
    "            if node.left != None:\n",
    "                queue.append(node.left)\n",
    "                queue.append(node.right)\n",
    "            else:\n",
    "                if len(node.data) != 0:\n",
    "                    node.left = Node(node.data_left)\n",
    "                    node.right = Node(node.data_right)\n",
    "                    #count += 1\n",
    "                    cur_layer.append(node.left.data)      # when leaf node is added add data\n",
    "                    cur_layer.append(node.right.data)\n",
    "\n",
    "\n",
    "    def addLayer(self):\n",
    "        self.depth += 1\n",
    "        # print(f\"-----Adding layer: {self.depth}-----\")\n",
    "        \n",
    "        cur_layer = []\n",
    "        self.splits_lst = []\n",
    "        self.add(self.root, self.splits_lst, cur_layer)\n",
    "\n",
    "        acc_data = cur_layer\n",
    "        correct = 0\n",
    "        incorrect = 0\n",
    "        for i in range(len(acc_data)):\n",
    "\n",
    "            dat = acc_data[i][:,-1]\n",
    "\n",
    "            zero = len(np.argwhere(dat==0))\n",
    "            one = len(np.argwhere(dat==1))\n",
    "\n",
    "            if zero > one:\n",
    "                correct += zero\n",
    "                incorrect += one\n",
    "            else:\n",
    "                correct += one\n",
    "                incorrect += zero\n",
    "            # print(zero, one)\n",
    "        #print(correct, incorrect)\n",
    "        \n",
    "        accuracy = round(correct/(correct + incorrect),3)\n",
    "\n",
    "        # print(f\"Training Accuracy: {accuracy}\")\n",
    "        return accuracy\n",
    "\n",
    "    def dfs(self, node, lst):\n",
    "\n",
    "        lst.append([node.feature, node.split, node.classification])\n",
    "\n",
    "        if node.left != None and node.right != None:\n",
    "            for idx in [node.left, node.right]:\n",
    "                self.dfs(idx,lst)\n",
    "\n",
    "\n",
    "    def testTree(self, data):\n",
    "        correct_class = 0\n",
    "        for t in data:\n",
    "            node = self.root\n",
    "            final_node = self.root\n",
    "            while node.left != None and node.classification != None:\n",
    "                if t[node.feature] <= node.split:\n",
    "                    node = node.left\n",
    "                else:\n",
    "                    node = node.right\n",
    "\n",
    "                final_node = node\n",
    "            if final_node.classification == t[-1]:\n",
    "                correct_class += 1\n",
    "\n",
    "        accuracy = round(correct_class/len(data),3)\n",
    "        # print(f\"Test Accuracy: {accuracy}\\n\")\n",
    "        return accuracy\n",
    "\n",
    "\n",
    "    def getDataClassification(self, data):\n",
    "\n",
    "        node = self.root\n",
    "        final_node = self.root\n",
    "        while node.left != None and node.classification != None:\n",
    "            if data[node.feature] <= node.split:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "\n",
    "            final_node = node\n",
    "\n",
    "        data_class = final_node.classification\n",
    "        return data_class\n",
    "\n",
    "\n",
    "def train_test(depth, train_data, test_data):\n",
    "\n",
    "    tree = Tree(Node(train_data))\n",
    "    tree.testTree(test_data)\n",
    "    \n",
    "    label = 1\n",
    "    for i in trange(depth, desc = \"Adding Layer {} -------> \".format(label)):\n",
    "        acc_train = tree.addLayer()\n",
    "        acc_test = tree.testTree(test_data)\n",
    "        sleep(0.01)\n",
    "        \n",
    "    print(f\"Training Accuracy: {acc_train}\")\n",
    "    print(f\"Test Accuracy: {acc_test}\")\n",
    "\n",
    "    return tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adff354e15db4ff3a30c27280fc7b391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Adding Layer 1 -------> ', max=3.0, style=ProgressStyle(dâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy: 0.751\n",
      "Test Accuracy: 0.701\n"
     ]
    }
   ],
   "source": [
    "### DEFINE DATASET ###\n",
    "file_name = \"datasets_228_482_diabetes.csv\"\n",
    "# file_name = \"data_banknote_authentication.csv\"\n",
    "train, test = loadDataset(file_name)\n",
    "\n",
    "### tree = train_test(depth, train_data, test_data) ###\n",
    "tree = train_test(3, train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Classify New Data Here ###\n",
    "data = test[0]\n",
    "print(tree.getDataClassification(data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
